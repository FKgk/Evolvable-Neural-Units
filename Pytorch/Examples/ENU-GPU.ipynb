{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear, Parameter, Module\n",
    "from torch import sigmoid, matmul, tanh, cat, clamp, stack, Tensor, randn, ones, zeros, device\n",
    "\n",
    "# torch.__version__ 1.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ENU(nn.Module):\n",
    "    def __init__(self, input_channels_size, output_channels_size, batch_size=1, memory_state_size=4, \n",
    "                 inner_gate_hidden_units=7, output_gate_hidden_units=4):\n",
    "        super(ENU, self).__init__()\n",
    "        \n",
    "        self.input_size = input_channels_size\n",
    "        self.h_size = memory_state_size\n",
    "        self.output_size = output_channels_size\n",
    "        self.inner_gate_hidden_units = inner_gate_hidden_units\n",
    "        self.output_gate_hidden_units = output_gate_hidden_units\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # reset gate\n",
    "        self.reset_gate = Linear(self.input_size + self.h_size + self.output_size, self.h_size).to(device)\n",
    "        self.reset_gate.weights = randn(self.input_size + self.h_size + self.output_size, self.h_size, requires_grad=True).to(device)\n",
    "        self.reset_gate.biass = randn(self.h_size, requires_grad=True).to(device)\n",
    "        \n",
    "        # update gate\n",
    "        self.update_gate = Linear(self.input_size + self.h_size + self.output_size, self.h_size).to(device)\n",
    "        self.reset_gate.weights = randn(self.input_size + self.h_size + self.output_size, self.h_size, requires_grad=True).to(device)\n",
    "        self.reset_gate.biass = randn(self.h_size, requires_grad=True).to(device)\n",
    "        \n",
    "        # cell gate\n",
    "        self.cell_gate = Linear(self.input_size + self.h_size + self.output_size, self.h_size).to(device)\n",
    "        self.reset_gate.weights = randn(self.input_size + self.h_size + self.output_size, self.h_size, requires_grad=True).to(device)\n",
    "        self.reset_gate.biass = randn(self.h_size, requires_grad=True).to(device)\n",
    "        \n",
    "        # output gate\n",
    "        self.output_gate = Linear(self.h_size, self.output_size).to(device)\n",
    "        self.reset_gate.weights = randn(self.h_size, self.output_size, requires_grad=True).to(device)\n",
    "        self.reset_gate.biass = randn(self.output_size, requires_grad=True).to(device)\n",
    "        \n",
    "        self.predict_gate = Linear(self.output_size, 1).to(device)\n",
    "        self.predict_gate.weights = randn(self.output_size, 1, requires_grad=True).to(device)\n",
    "        self.predict_gate.biass = randn(1, requires_grad=True).to(device)\n",
    "        \n",
    "        # pre memory sate and output\n",
    "        self.h = zeros(self.batch_size, 1, self.h_size)\n",
    "        self.o = zeros(self.batch_size, 1, self.output_size)\n",
    "    \n",
    "    def Reset_Gate(self, data):\n",
    "        return self.reset_gate(data)\n",
    "\n",
    "    def Update_Gate(self, data):\n",
    "        return self.update_gate(data)\n",
    "\n",
    "    def Cell_Gate(self, data):\n",
    "        return self.cell_gate(data)\n",
    "\n",
    "    def Output_Gate(self, data):\n",
    "        return self.output_gate(data)\n",
    "    \n",
    "    def step(self, x): # input each SIze(1, 3)\n",
    "        self.input = cat((self.h, self.o, x), -1) # Size (1, 10)\n",
    "\n",
    "        # Reset Gate\n",
    "        self.r = sigmoid(self.Reset_Gate(self.input)) # Size (1, 4)\n",
    "        # Update Gate\n",
    "        self.z = sigmoid(self.Update_Gate(self.input)) # Size (1, 4)\n",
    "        \n",
    "        # Cell Gate\n",
    "        self.cell_gate_input = cat((self.r * self.h, self.o, x), -1) # Size(1, 10)\n",
    "        self.h_bar = tanh(self.Cell_Gate(self.cell_gate_input)) # Size (1, 4)\n",
    "        \n",
    "        # Memory State\n",
    "        self.h = (1 - self.z) * self.h + self.z * self.h_bar # new memory state \n",
    "        \n",
    "        # Output Gate\n",
    "        self.o = clamp(self.Output_Gate(self.h), 0, 1) # Size (1, 3)\n",
    "\n",
    "        return self.o\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x : (batch_size, sequence, input_channels)\n",
    "        self.h = zeros(x.size()[0], 1, self.h_size).to(device)\n",
    "        self.o = zeros(x.size()[0], 1, self.output_size).to(device)\n",
    "        \n",
    "        for i in range(x.size()[1]):\n",
    "            output = self.step(x[:, i, :].view(self.batch_size, 1, self.input_size))\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def predict(self, output=None):\n",
    "        if output is None:\n",
    "            return self.predict_gate(self.o)\n",
    "        else:\n",
    "            return self.predict_gate(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
